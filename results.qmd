# Results

Per the Methods section, the performance of the proposed jackknife estimator was compared to two leading methods in the literature, Rubin's rules following multiple imputation and Bootstrap resampling prior to multiple imputation. The methods were compared concerning the coverage probabilities they generated, the widths of their respective confidence intervals, their computational expense, and the bias of their point estimators.

```{r, include=FALSE}
# Aggregated code here for organization, make it available in an appendix.
library(tidyverse)
library(ggpubr)

combined_results <- read_csv("final_sim_data_agg.csv") %>%
  select(-"...1")

benchmark_res <- read.csv("benchmark_detailed_res.csv") %>%
  select(-X) %>%
  group_by(expr) %>%
  summarise("Mean Time (seconds/iteration)" = mean(time)/1e6/100, 
            "Median Time (seconds/iteration)" = median(time)/1e6/100, 
            "SD of Time (seconds/iteration)" = sd(time)/1e6/100) %>%
  rename("Method" = expr)

benchmark_res_ord <- benchmark_res[c(2,1,3),] 

jackknife_coverage <- 
  round((sum(combined_results$true_var < combined_results$UB &
               combined_results$true_var > combined_results$LB) / nrow(combined_results))*100,2)

rubin_coverage <- 
  round((sum(combined_results$true_var < combined_results$UB_rub &
               combined_results$true_var > combined_results$LB_rub) / nrow(combined_results))*100,2)

boot_coverage <- 
  round((sum(combined_results$true_var < combined_results$UB_boot &
               combined_results$true_var > combined_results$LB_boot) / nrow(combined_results))*100,2)

ci_sum <- tibble(
  "Method" = c("Jackknife", "Bootstrap", "Rubin's Rules"), 
  
  "Coverage Probability" = c(jackknife_coverage, rubin_coverage, boot_coverage), 
  
  "Median C.I. Width" = c(median(combined_results$jackknife_width), median(combined_results$boot_width), median(combined_results$rubin_width)), 
  
  "Mean C.I. Width" = c(mean(combined_results$jackknife_width), mean(combined_results$boot_width), mean(combined_results$rubin_width)), 
  
  "SD of C.I. Width" = c(sd(combined_results$jackknife_width), sd(combined_results$boot_width), sd(combined_results$rubin_width))
)

point_estimate_sum <- tibble(
  "Method" = c("Jackknife", "Bootstrap", "Rubin's Rules"), 
  
  "Median Point Estimates " = c(median(combined_results$point_estimate), median(combined_results$point_estimate_boot), median(combined_results$point_estimate_rub)), 
  
  "Mean Point Estimates" = c(mean(combined_results$point_estimate), mean(combined_results$point_estimate_boot), mean(combined_results$point_estimate_rub)), 
  
  "SD of Point Estimates" = c(sd(combined_results$point_estimate), sd(combined_results$point_estimate_boot), sd(combined_results$point_estimate_rub))
)

set.seed(234)
jackk <- combined_results %>%
  sample_n(1e2, replace = FALSE) %>%
  mutate(covers = ifelse(UB > true_var & true_var > LB, "Covers", "Does Not Cover")) %>%
  ggplot(., aes(x = 1:100)) + 
  geom_errorbar(aes(ymin = LB, ymax = UB, color = covers)) + 
  theme_bw() + 
  #coord_flip() + 
  labs(
    x = latex2exp::TeX("$i^{th} iteration"), 
    y = "C.I."
  ) + 
  geom_hline(yintercept = combined_results$true_var) + 
  scale_color_manual(name = NULL, values=c("#999999", "#FF0000")) + 
  ggtitle("Jackknife Estimator") + 
  xlim(c(0,100)) + 
  ylim(c(-2.5,5))

set.seed(24123)
boot <- combined_results %>%
  sample_n(1e2, replace = FALSE) %>%
  mutate(covers = ifelse(UB_boot > true_var & true_var > LB_boot, "Covers", "Does Not Cover")) %>%
  ggplot(., aes(x = 1:100)) + 
  geom_errorbar(aes(ymin = LB_boot, ymax = UB_boot, color = covers)) + 
  theme_bw() + 
  #coord_flip() + 
  labs(
    x = latex2exp::TeX("$i^{th} iteration"), 
    y = "C.I."
  ) + 
  geom_hline(yintercept = combined_results$true_var) + 
  scale_color_manual(name = NULL, values=c("#999999", "#FF0000")) + 
  ggtitle("Bootstrap Estimator") + 
  xlim(c(0,100)) + 
  ylim(c(-2.5,5))

set.seed(234)
rubin <- combined_results %>%
  sample_n(1e2, replace = FALSE) %>%
  mutate(covers = ifelse(UB_rub > true_var & true_var > LB_rub, "Covers", "Does Not Cover")) %>%
  ggplot(., aes(x = 1:100)) + 
  geom_errorbar(aes(ymin = LB_rub, ymax = UB_rub, color = covers)) + 
  theme_bw() + 
  #coord_flip() + 
  labs(
    x = latex2exp::TeX("$i^{th} iteration"), 
    y = "C.I."
  ) + 
  geom_hline(yintercept = combined_results$true_var) + 
  scale_color_manual(name = NULL, values=c("#999999", "#FF0000")) + 
  ggtitle("Rubin's Rules") + 
  xlim(c(0,100)) + 
  ylim(c(-2.5,5))

point_dist <- reshape2::melt(combined_results[c("point_estimate_rub", "point_estimate", "point_estimate_boot")]) %>%
  ggplot(data = .,
         aes(x = value - 2, fill = variable, color = variable)) + 
  geom_density(aes(y = ..density..), alpha = 0.25) + 
  theme(axis.title.y = element_blank(), 
        panel.spacing=unit(1.5,"lines")) + 
  theme_bw() + 
  theme(axis.title.y = element_blank(), 
        panel.spacing=unit(1.5,"lines"), 
        strip.text = element_text(
          size = 9)) + 
  labs(
    x = latex2exp::TeX("$\\widehat{\\beta_1} - \\beta_1")
  ) + 
  scale_fill_discrete(name = "Method", labels = c("Rubin's Rules", "Jackknife", "Bootstrap")) + 
  scale_color_discrete(name = "Method", labels = c("Rubin's Rules", "Jackknife", "Bootstrap"))

benchmark_plot <- read.csv("benchmark_detailed_res.csv") %>%
  select(-X) %>%
  ggplot(., aes(x = expr, y = time/1e6/100)) + 
  geom_violin() + 
  scale_y_log10() + 
  theme_bw() + 
  ggtitle("Benchmark for Methods Examined") + 
  coord_flip() + 
  labs(
    y = "Time (seconds/iteration)"
  ) + 
  theme(axis.title.y = element_blank())
```

## Point Estimates

All methods, perhaps with the exception of Rubin's rules, produced reasonable point estimates with minimal bias. Rubin's rules resulted in slightly anticonservative point estimates with greater standard deviation, indicative of a statistically inefficient estimator with high variability. This finding is unsurprising given the literature on Rubin's rules and its performance under uncongeniality.

In contrast, it is noted that both resampling methods examined provide nearly unbiased point estimates with smaller standard deviations compared to Rubin's rules. Again, given the literature on uncongeniality, this finding was unsurprising; however, given the lack of both empirical and theoretical justification for the bootstrap approach in small sample sizes, the desirable properties noted are worthy of further examination. Between all three methods, nevertheless, it is noted that the proposed jackknife estimator produced estimates with the smallest amount of bias, as well as the smallest standard deviation, an observation perhaps better observed in @sec-dist, where the distribution of the biases of the point estimates is compared. From the kernel density plots presented, it is evident that Rubin's rules slightly underestimate the parameter. Compared to Rubin's rules, both resampling approaches provide point estimates that are nearly unbiased; however, it is noted that the bootstrap estimates, despite being centered near zero, are slightly more dispersed compared to the jackknife estimates, which present as a narrow distribution centered at zero. This observation is justified by the values provided in @sec-point which demonstrate that the jackknife point estimates have a smaller standard deviation than the bootstrap approach and Rubin's rules.

From a point estimation perspective, the statistically desirable properties of the jackknife estimator, alongside its theoretical and empirical justification when used with small sample sizes, yield it a desirable estimator. 

### Summary of Point Estimation Properties {#sec-point}
```{r, warning=FALSE, echo = FALSE}
point_estimate_sum
```

### Distribution of Point Estimator Bias {#sec-dist}

```{r, warning=FALSE, message=FALSE}
point_dist
```

## Confidence Intervals {#sec-ci}

Over-coverage of confidence intervals is noted across all methods; however, particulary with the jackknife and bootstrap approaches, such over-coverage is only slightly over the nominal, as such, they are likely not of concern and can be explained, in part, by the Monte Carlo standard error for the true coverage proabability of a 95% confidence interval. Among the three methods noted, Rubin's rules, by a significant margin, deviates from the nominal coverage, indicative of an overly conservative estimator. An argument could be made, particulary in the case of biological studies that an overly conservative estimator is safer than one that is anti-conservative; however, the statistical inefficieny created by conservative estimators can be of concern, particulary in instances where small sample sizes are present or the test being utilized already has low statistical power. Comparing these methods concerning confidence interval width, it is noted that both resampling approaches provide  narrower confidence intervals, with the jackknife approach providing the narrowest confidence intervals by a wide margin. In instances where nominal, or near-nominal coverage is reached, narrower confidence intervals are indicative of more efficient estimators. Given the near-nominal coverage noted with the jackknife estimator, combined with the narrow confidence intervals it produces, its superity to the two other methods may be inferred. 

A visual overview of the coverage probabilities may be noted in @sec-zip, where zipper plots of the methods are presented utilizing a simple random sample of 100 observations from the Monte Carlo simulation results of all methods examined. Given the small number of subsamples examined for visual clarity, the plots may not be indicative of the larger results presented above; however, they provide an appreciation for the meaning of coverage probabilities. 

```{r, warning=FALSE, echo=FALSE}
ci_sum
```

### Zipper Plots for Confidence Interval Coverage {#sec-zip}

```{r}
ggarrange(jackk, boot, rubin, ncol = 1, nrow = 3, common.legend = TRUE, legend="right")
```

## Performance Benchmark Results

Finally, the three methods are compared concerning their computational expenses. Comparing the two approaches, which require further resampling, it is noted that the bootstrap approach takes nearly ten times longer than the jackknife approach per iteration. Unsurprisingly, Rubin's rules, which do not rely on any further resampling besides the one performed during multiple imputation, was the fastest approach. However, given its biased estimates under uncongeniality or misspecification, the computational advantage it brings to the table adds very little value. 

Despite generating the same number of subsamples $(n = 200)$, albeit in contrasting manners, with the same number of imputations $(m = 2)$ and iterations $(maxit = 5)$, it is surprising that the bootstrap approach took nearly ten times longer per iterations to provide estimates. Regardless, the significantly reduced computational expense of the jackknife estimator yields it superior to the bootstrap approach under this particular scenario. 

```{r, warning=FALSE, echo=FALSE}
benchmark_res_ord
```

```{r, warning=FALSE, message=FALSE}
benchmark_plot
```

